02 - Natural Images
===================

+ Erster Ordnung: Pixel einzeln betrachten
    + Histogramm
        + die Verteilung der log(intensity) ist bei natürlichen Bildern oft symmetrisch
    + Kontrast
        + Kontrastverbesserung durch normalisieren des kumulativen Histograms
    + Momente berechnen (Formel)
        + misst die "Gaussheit"
        + k=0: Anzahl
        + k=1: Mittelwert
        + k=2: Varianz
        + k=3: Skewness (Asymmetrie)
            + bei glossy Oberflächen
        + k=4: Kurtosis (Peakness)
    + Nachteil: Keine räumliche Information
+ Zweiter Ordnung: Beziehung zwischen Nachbarpixeln betrachten (Gradienten)
    + Gradient ist meistens nahe 0 -> einfarbige Flächen
    + Pearson Correlation misst lineare Abhängigkeit von Verteilungen?
        + Zwischen 1 (identisch), 0 (tritt auf bei fehlender Korrelation) und -1 (inverse Verteilung)
        + in natürlichen Bildern oft 0.8 und 0.95 zwischen benachbarten Pixeln
        + auch Korrelation bei Pixeln, die weiter voneinander entfernt sind!
+ Higher Order: Pixelblöcke, zB 3x3
    + Topologie der kontrastreichsten Blöcke ist eine kleinsche Flasche!
    + Phaseninformationen in der FT enthalten die wesentlichen Informationen des Bildes
    + Wavelet Transformation erlaubt Kompression, Kantenerkennung, Frequenzbetrachtungen

03 - Image Processing
=====================

+ Spatial Filtering
    + convolution mit 3x3 filter kernel
    + Tiefpassfilter
        + summe der kernelwerte: 1
        + entfernt noise -> smoothing
        + Typen
            + mean (zB 1/9 * (3x3 mit Einsen))
            + gauß
            + median
                + keine convolution!
                + pixel nach wert ordnen, median nehmen
                + nichtlinear
                + gut für unvollständige Bilder, und binärnoise (zB photon noise)
    + Hochpassfilter
        + zB 1/9 * (3x3 mit -1 und 8 in der Mitte)
        + summe der kernelwerte: 0
        + verstärkt noise
        + derivative filters zur Gradientenerkennung
            sobel operator [-1 -2 -1, 0 0 0, 1 2 1] ist Ableitung nach y
        + stabiler: vorher tiefpassfiltern. bzw den kernel gaußfiltern
        + zweiter ableitung: [-1 2 -1] bzw [0 -1 0, -1 4 -1, 0 -1 0]
            + oder marr-hildreth operator ("mexican hat")
                + sharp gaussian - wide gaussian
                + symmetrisch -> in alle richtungen gleich
                + geschlossene konturen
                + funzt mit blurry edges
                + noise unterdrückung
                + zu viele kanten
             + findet zero-crossings
         + canny edge detector
            + doppelkanten für schmale linien
        + probleme
            + dünne linien werden verdoppelt
            + manuelles parameter fiddling
+ hough filter
    + für jeden pixel des kantenbildes im 2D parameter space alle pixel erhöhen, dessen linien durch den pixel führen könnten
+ feature point detection
    + harris corner detector
        + fenster suchen, die sich beim verschieben genug ändern
+ point feature corresponcdence matching
    + block-based
    + sum-of-squared-error
    + sum-of-squared-difference
        + beide anfällig gegen helligkeitsunterschiede
    + normalized cross-correlation
        + gut!
    + SIFT feature detector
        + unabhängig von verdeckung, rotation, skalierung, beleuchtung, noise
+ probleme: rauschen, tiefenunschärfe

04 - Projective Transformation
==============================

+ Homography = Projektive Transformation
    + Punkt auf einer Ebene auf eine andere projizieren, hinsichtlich eines Projektionszentrums
    + Taxonomie:
        + euclidean (3 dof)
            + rotation und translation in x und y
        + similarity (4 dof)
            + + skalierung
        + affine (6 dof)
            + + scherung in x und y
            + parallele linien bleiben es
            + Matrix H = [a b tx, c d ty, 0 0 1]
            + man braucht 3 Punktkorrespondenzen
        + projective (8 dof)
            + stauchen in x und y
            + man braucht 4 linear unabhängige Punktkorrespondenzen
+ Projektive lösen
    + Normalisierung von x
    + und x'
    + Denormalisieren
    + DLT
+ Panoramas bauen
    + Feature Punkte finden
    + Featurekorrespondenzen
    + Falsche Korrespondenzen finden: RANSAC
        + benögtigt: vieeeele Korrespondenzen
            + man benötigt zB 20-40, man kann das schätzen
        + iteriert, bis irgendwas nicht mehr besser wird...
    + auch über die "guten" Korrespondenzen muss man dann noch H optimieren
        + oder noch toller: Levenberg-Marquardt-Iteration

05 - Geometry from images
=========================

+ Bestandteile von Bildformationen
    + 3D-Geometrie
    + Textur
    + BRDF
    + Illumination
+ Kamerakalibrierung
    + extrinsische (6)
        + Position des Projektionszentrums
        + Richtung der optischen Achse
        + Rotation um die Achse
    + intrinsische
        + Focal length
        + Pixel width & height
        + image plane shift
+ Perspektive Projektion
    + hoomogene Formulierung: [s*x, s*y, s] = [f 0 0 0, 0 f 0 0, 0 0 1 0] * [X, Y, Z, 1]
    + von Abständen zu Pixeln:
        + u = u_c + x/pixel_width, entsprechen für v und y
        + Matrixschreibweise: [s*u, s*v, s] =
            [f/pw 0    u_c 0
             0    f/ph v_c 0
             0    0    1   0]*[X, Y, Z, 1] = P * M~
+ Kameramatrix K = [a b c t_x
                    d e f t_y
                    g h i t_z
                    0 0 0 1  ] enthält Translation und Rotation der Kamera (6 dof)
+ Welt-zu-Kamera: Kamera-Kalibrations-Matrix C = P*K
    + die wollen wir schätzen! 11 dof, einer kann normiert werden
    + brauchen 6 Punktkorrespondenzen
        + zB mit Kalibrierkörper (wie genau? Folie 11-15 )
+ Stereo-Rekonstruktion
    + zwei Kameras kallibiert: Punkt mit unbekanntem Abstand erzeugt in anderer Kamera Epipolarlinie
    + Kamera-baseline schneidet die Bildebene bei den Epipolen, dort gehen alle Epipolarlinien durch
    + Punkt kann dann durchs Schneiden der Strahlen rekonstruiert werden
    + nun: Nur Punktkorrespondenzen bekannt
        + Epipolarlinie berechnen mit F * x
        + Fundamentalmatrix F = e' x H_pi
            e': epipolarpunkt im zweiten Bild
            H_pi: Projektive Matrix, die x auf x' mappt
        + mit einigen Punktpaaren kann man dann nach F lösen ^^
        + gut: bei der Berechnung auf 1 normieren
+ Bilder rektifizieren
    + beide Bilder auf große Leinwand projezieren, die parallel zu der baseline läuft (von den Projektionszentren aus), dann Homographie auf gemeinsame Bildebene
    + dann laufen die Epipolarlinien parallel
    + Nachteil: Resampeln nötig
    + Disparität d = x_links - x_rechts = f*b/z
+ Matching
    + besten nxn-Block suchen
    + Constraints:
        + Reihenfolge des Auftauchens bleibt erhalten
        + Uniqueness: Korrespondenz der Punkte ist bidirektional
        + Disparität innerhalb eines Bereiches
        + Kontinuierlichkeit der Disparität
+ Mergen von Tiefenkarten
    + Iterative Closest Point Algorithm
        + fügt zwei 3D-Oberflächen zusammen durch iteratives Verfahren
    + Volumetric Depth Map Merging
        + voxel wegschneiden aus verschiedenen Perspektiven
+ Shape-from-silhouette
    + siluetten aus verschiedenen Perspektiven schneiden -> Konvexe hülle des Objektes
    + schnell

06 - Shape from X
=================

+ Binocular vision
    + Konvergenz ("schielen")
    + Stereo
+ Monocular vision
    + Fokus
    + Perspektive
    + Textur
    + Schattierung
    + Konturen
    + 3D-Regeln
    + Parallaxe
+ Shape from X (except stereo)
    + Texture
        + nutzt Verformung von Texturprimitiven
    + Focus
        + scharfe Bereiche suchen (zB Wavelet-Analyse oder Hochpassfilter)
    + Shading
        + Reflectance Map: Pixelintensität als Funktion der Oberflächenorientierung des Punktes
            + bei lambertschen Oberflächen: Reflektanz proportional zum Winkel zwischen Normale und Lichteinfallrichtung
            + auch bei nichtlambertschen kann man das in die RM reinnehmen
        + Photometric stereo
            + Objekt bei drei Beleuchtungen aufnehmen
            + Jede definiert eine Ellipse auf der 2D-Winkel-Karte
            + drei davon schneiden sich in einem Punkt
+ Tomography
    + Volumen statt Oberfläche
    + Objekt muss semi-transparent sein (keine Streuung oder Reflektion)
    + Radon Tranform
        + Röntgenstrahl wird abgeschwächt, verbleibende Stärke wird registriert
            + Wert ist Integral der Abschwächung
        + Vorgehensweise: Objekt in verschiedenen Winkeln durchleuchten, Resultate Fourier-transformieren
            + Resultat ist in der Mitte dichter
        + Nachteile
            + Bilder müssen sehr regelmäßig aufgenommen werden
            + Drehachse darf sich nicht verschieben
            + Röntenquelle ist Punktlichtquelle, keine parallelen Strahlen
    + Algebraic reconstruction
        + Volumen in Grid diskretisieren
        + Jeder Strahl macht ein Gleichungssystem der Form (Anteil von voxel an Strahl)*Intensität + ... + ... = Messwert

07 - Reflectance
================

+ Surfaces
    + matt, glossy, mirror
    + anisotopisch: Drehrichtung ist wichtig (gebürstetes Metall zB)
    + transparent
    + transluzent
    + volumetrische Strukturen
+ Taxonomy of appereance representations
    + gloss (1D/0D)
    + isotropic BRDF (3D)
    + (anisotropic) BRDF (4D)
        + spatially varying BRDF (6D) (nicht überall gleiche BRDF)
        + bidirectional subsurface scattering RDF (BSSRDF) (6D)
    + single-wavelength scattering function (BSSRDF) (8D)
    + scattering function (ganzes Spektrum betrachten) (9D)
    + zeiteigenschaften, fluoreszenz (12D)
+ BRDF
    + f(omega_o, x, omega_i)
        x ist der Punkt, o und i die in und out Richtungen des Lichts
    + Darstellungen
        + Tabelle
        + zwei 2D-Funktionen draus machen
        + Basisfunktionen zB Wavelets
        + analytische Modelle machen CGler gerne
+ BRDF measurement system
    + Digitizing
        + 3D
        + 3D + Textur
            + keine Neubeleuchtung möglich
        + 3D + Textur + varying BRDF
    + also Ziel: Reflektionseigenschaften jedes Texels messen
    + viele Fotos mit unterschiedlicher, bekannter Beleuchtung
    + Setup: 3D scanner, Kamera, Punktlichtquelle, dunkler Raum, Kalibrierkörper (Schachbrett, Kugeln)
    + Oberfläche in flachgedrückte patches zerlegen (Texturatlas)
    + passende 3D-Blickrichtung finden über Umriss
    + Kugeln verraten Position der Kamera (Blitz) und der Punktlichtquelle
    + Lumitexel sammeln: Position, Normale, sample mit radianz, lichtrichtung, blickrichtung

08 - Photometric Information
============================

+ Ziel: Farbe, Textur, Reflektionseigenschaften erkennen
+ General Tool: Kamera
+ Modulation Transfer Function
    + beschreibe die Eigenschaften des optischen Systems im Frequenzraum
    + Point Spread Function (Bild einer Punktlichtquelle)
    + MTF (FT der PSF)
        + misst wie stark image detail contrast vom System wiedergegeben wird
    + Line Spread Function (1D slice der MTF)
    + MTF measurement: Slanted Edge Method
        + low-contrast schräge Kante aufnehmen
        + Linie auf Kante fitten
        + aufgenommenes Bild auf senkrechte zu kante projizieren
        + FT des Profils -> MTF
    + bei Frequenzen über Nyquist: Aliasing
    + Bild: Von 1 auf ~ 0 bei 0.5 cycles/pixel (Folie 21)
        + darunter blurring, darüber sharpening. Rechts von Nyquist aliasing
    + Effektive Auflösung dort, wo die MTF unter 0.1 fällt
+ HDR
    + dynamic range: Verhältnis von hellstem zu dunkelstem (nicht-null) wert
        1:100000 oder 5 größenordnungen oder 100 dB
    + Quellen: Helligkeitsunterschiede spekulare highlights vs dunkle diffuse materialien (0.5% reflektanz)
    + standard CCD sensor ca 1:100,000,000 (mit mehreren Bildern)
    + ein Bild: 1:1000
    + daher Grundverfahren: mehrere Bilder mit Response curves gewichtet kombinieren -> HDR Bild
    + Verfahren
        + Robertson
            + Einfach
            + konvergiert schnell
            + benutzt alle vorhandenen Bilder
            + manche Szenen gehen nicht gut (zB wenige monochrome Farbflächen)
    + Anzahl Bilder? Faktor 4 zwischen Exposures oft ausreichend
    + für verwackelte Bilder: Median Threshold Bitmap
        + Histogramm, medians suchen, rechts und links binarisieren
        + erlaubt mappen von Bildern aufeinander
    + für bewegte Bilder
        + andere Hardware (in der Optik oder im Chip)
    + HDR auf dem Bildschirm darstellen?
        + tone-mapping zum komprimieren des dynamischen bereichs
+ White balancing
    + Annahmen über Spektrogramm der Lichtquelle
+ ICC Profile
    + für Kameras, Monitore, Drucker
+ Lighting and environment
    + Halogenlampen machen gutes Spektrum, sind fast Punktlichtquellen

09 - Image-based rendering
==========================

+ Ziel: Dinge aus anderen Perspektiven rendern
    + Man kann die Bilder *berechnen*
    + oder *nachschlagen*
+ Plenoptische Funktion
    + 7D-Funktion die die radiance in Abhängigkeit der Wellenlänge, des Ortes, unter betrachtungswinkel zu einem Zeitpunkt
    + Herausforderungen:
        + Aufnahme
            + continuierlich -> Diskretisierung
            + hochdimensional -> Reduktion
                + Zeit und Wellenlänge raus -> 5D
                + transparenter Raum, muss geschickt parametrisiert werden -> 4D
                + z-Achse weg (Concentric Mosaics) -> 3D
                + fixierter Viewpoint (Panoramas) -> 2D
        + Rendering
            + continuierlich -> look up
            + diskretisierte Daten -> re-sample/interpolate
+ Pure IBR
    + Panoramas
        + Projezierung auf Kugel
            + Flächen bleiben regelmäßig
            + Aber: viel Resampling
        + Zylinder
            + einfache Abfrage
            + vertikale Views nicht darstellbar
        + Würfel
            + einfach, alle Richtungen
            + Distortion an den Kanten
    + Concentric Mosaics
        + viewpoint auf fester Ebene
        + rotierender Balken, mehrere Kameras darauf machen Aufnahmen
        + Für jeden Ring ein Panorama
        + für neuen Punkt: Für alle Richtungen beste Tangenten an Ringen suchen, Panorama zusammensetzen
    + Light Field Rendering
        + volle Parallaxe in alle Richtungen
        + für eine Aufnahmeebene: Grid von Fotos
        + für neue Blickrichtung: Beste Strahlen der alten Bilder finden, dann optional noch interpolieren
    + zu viele Bilder nötig, nicht praktikabel
        + deshalb Geometrie mit rein
        + zB voxel modell, damit dann zwischenbilder erzeugen
+ Geometry + IBR
    + Lumigraph
        + wieder Grid von Aufnahmen mit Tiefenkarten
        + für neuen Strahl beste Oberflächenpunkte finden
        + parallax ist drin
        + reduziertes aliasing
        + verdeckte Regionen trotzdem ein Problem
    + View Morping
        + Kamera zwischen echten Aufnahmen hin- und herbewegen können
    + View-dependent Texture mapping
        + Fotos + exakte Geometrie
    + Surface Light Fields
        + auch Fotos + exakte Geometrie??
        + irgendwas mit Lumispheres

10 - Motion
===========

+ 2D motion
    + korrespondenz-problem
        + bei seitlicher Kamerabewegung: 1D-Suche
        + probleme: überdeckung, entdeckung, beleuchtungsänderungen
        + viele Anwendungen
    + motion field
        + 2D-projektion des scene flows
    + Optical Flow
        + aproximation des motion fields
        + annahmen
            + helligkeit bleibt gleich
            + bewegung ist "klein" (oft <1 pixel)
        + bewegung entlang des Gradienten kann nicht erkannt werden (aperture problem)
        + probleme, wenn die annahmen nicht zutreffen
            + wenn bewegung mehr als 1 pixel: Multi-resolution approach
        + bei globaler affinen abbildung braucht man nur wenige parameter
        + noch mehr Probleme: temporale effekte (cartwheel)
        + beschränkungen
            + verdeckung, beleuchtungseffekte, bla
+ 3D motion
    + scene flow
        + wahre korrespondenzen in 3D
    + spacetime coherence
        + glatte bewegungen über die zeit aus einzelbildern
        + visuelle hülle? TODO 40
            + daraus glatte spacetime-coherent reconstruction
+ perception-based interpolation
    + ziel: interpolation zwischen unkalibrierten bildern mit ähnlichen inhalten
    + verfahren
        + starke kanten suchen, dann farbdiffusion von denen aus
        + kantenpixel zuordnen, dann warping berechnen
        + voll tolle erbnisse \o/ \o/

11 - Different Stuff
====================

- Photo Zoom: Fotos aus mehreren Abständen, daraus einen flüssigen Zoom berechnen
- Alternate Exposure Imaging: Abwechselnd lang und kurz belichten, daraus Flussinformationen
- Floating Textures: Besseres Texturemapping aus unbekannten Richtungen auf approximierter Geometrie mittels Fluss!

Klausur
=======

+ 50% multiple choice (falsch: Minuspunkte, teilweise auch mehrere Antworten richtig), 50% Aufgaben
+ Taschenrechner erlaubt
+ homogener Mathequatsch - Geraden schneiden etc
    + good for relating points and lines
    + für 2D: Dritte Koordinate hinzufügen
    + erlaubt vor allem Translation durch 3x3-Matrix darzustellen
    + Geradendarstellung:
        + (a b c) als Normale auf der Ebene, die durch den Ursprung und der Geraden, um 1 in z verschoben
            + Gerade erfüllt dann ax + by + c = 0
    + Test, ob Punkt auf Linie liegt: x*l = 0, wobei l = (a b c), x = (x y w)
    + Schnittpunkt von Linien: l' cross l = x
    + Linie durch zwei Punkte: x' cross x = l
+ was können Projektionen
+ Kamerageometrie - "4 Linien, Strahlensatz"
    + perspektivische Projektion (Pinhole)
        + x = f*r/g bzw f/x = g/r
            x: Abstand x in der Bildebene (Koordinate)
            f: Abstand der Bildebene vom Loch (fokale Länge)
            r: Abstand des Punktes von der Mittelachse
            g: Abstand des Punktes vom Loch
        + Eigenschaften
            + Geraden -> Geraden
            + bei Ebenen parallel zur Bildebene -> gleiche Winkel
            + doppelter Abstand -> halbe Größe
            + doppelte fokale Länge -> verdoppelte Größe
            + Verschiebung parallel zur Bildebene -> Verschiebung
    + parallele Projektion
        + wie bei starken tele-lenses
+ Materialiengeschichten, BRDF: was ist damit einfach/schwierig?
+ Korrespondenzschätzungen: Begrifflichkeiten, 2D, 3D, Folien mit tanzender Figur o_O (keine Formeln)
+ 2D image processing, Filter, was funktioniert gut/schlecht?
+ menschliche Wahrnehmung: Nix biologisches
+ IBR, Lichtfeldrendering, Lumigraph, was unterscheidet die
+ keine Funktionsweise von Algorithmen
+ fehlende Folien in 5/space carving nicht relevant
+ keine Interna von Optimierungsverfahren
+ keine Hardware
+ nicht große Mengen Formeln

Lernen
======

+ Momente erster Ordnung
    Anzahl, Mittelwert, Varianz, Skewness, Kurtosis
+ Wie heißt der Wellenschnittalgo
    Hough Filter
+ Die 3 Kantenerkennungsdingis und ihre Eigenschaften
    Sobel filter
        eine Richtung
    Marr-Hildreth operator
        Richtungssymmetrisch
        geschlossene Konturen, aber zu viele
    Canny edge detector
        Doppelkanten
+ Feature punkt such dinge
    Harris corner detector, SIFT
+ Kameramatrizen (siehe oben)
+ Wie heißt das zusammen?
    Kamera-Kalibrations-Matrix
+ Verfahren für 3D-rekonstruktion
    Volumetric Depth Map Merging, Space Carving, Iterative Closest Point Algo
- IBR-Verfahren
    Light field rendering, concentric mosaics, lumigraph, view morphing, surface light fields, view-dependent texture mapping
+ bewegungsfluss-dinge
    Scene Flow, Motion Flow, Optical Flow
- interpolation algorithms
    perception-based interpolation, spacetime coherence
+ wie heißt die IBR-Funktion?
    plenoptische
+ transformations-arten
    euclidean 3
    similarity 4
    affine 6
    projective 8
+ projektive transformation aus >= 4 korrespondenzen
    DLT
+ falsche korrespondenzen
    RANSAC
- korrespondenzen optimieren
    Gauss-Newton
- dreikreise
    photometric stereo
- drehwinkelabhängigkeit
    anisotropisch
+ BRDF taxonomie
    0D/1D gloss
    3D isotropic BRDF
    4D (anisotropic) BRDF
    6D positional-varying BRDF oder subsurface scattering
    8D single wavelength
    9D ganzes spektrum
    12D + zeit und fluoreszenz
+ was geht nicht gut mit BRDF
    volumetrische strukturen
    durchsichtiger kram
- frequenzabbildungsmessung
    Modulation Transfer Function, Line Spread Function -> slanted edge
- HDR-Berechnung
    Robertson
- verwackelte bilder aufeinander mappen
    Median Threshold Bitmap
- Volumenrekonstruktion
    Tomographie
